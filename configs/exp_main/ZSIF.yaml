_target_: src.exp.ZSIF_main.Exp_Main

name: ZSIF

#数据
dataloader:
  _target_: src.data_provider.tscontext_dataloader.TSContextDataModule
  dataset:
    data_dir: ${paths.data_dir}
    stats_path: ${paths.stats_path}
#    context_channels: null
#    optflow_channels: null
#    context_channels: [ IR_108, VIS008, WV_073 ]
    context_channels: [ IR_108, VIS006, VIS008, WV_062, WV_073 ]
#    context_channels: [ IR_039, IR_087, IR_108, VIS006, VIS008, WV_062, WV_073 ]
    optflow_channels: [ IR_108_vx, IR_108_vy, WV_062_vx, WV_062_vy, WV_073_vx, WV_073_vy ]
    ts_channels: [ 'GHI', 'DIF [W/m**2]', 'DIR [W/m**2]', 'PoPoPoPo [hPa]', 'dhi', 'dni', 'ghi' ]
#    ts_channels: ['GHI', 'PoPoPoPo [hPa]', 'DIF [W/m**2]', 'DIR [W/m**2]',  'ghi', 'dni', 'dhi']
    ts_target_channels: [ 'GHI' ]
    years:
      train: [ "2008_nonhrv", "2009_nonhrv","2010_nonhrv", "2011_nonhrv","2012_nonhrv", "2013_nonhrv", "2014_nonhrv", "2015_nonhrv", "2016_nonhrv" ]
#      train: [ "2009_nonhrv" ]
      val: [ "2017_nonhrv", "2018_nonhrv", "2019_nonhrv" ]
      test: [ "2020_nonhrv", "2021_nonhrv", "2022_nonhrv" ]
#      test: [ "2017_nonhrv", "2018_nonhrv", "2019_nonhrv" ]
    stations:
      train: [ "PCCI_20082022_IZA", "PCCI_20082022_CNR", "PCCI_20082022_PAL" ]
#      train: [ "PCCI_20082022_IZA"]
      val: [ "PCCI_20082022_PAY" ]
      test: [ "PCCI_20082022_CAB" ]
#      test: [ "PCCI_20082022_TAM"]
    image_size: null
    crop: null
    seq_len: 48
    label_len: 0
    pred_len: 48
    use_target: True
  batch_size: 64
  num_workers: 16
  pin_memory: True

#模型
model:
#  _target_: src.models.cross_vivit_bis.RoCrossViViT_bis
  use_pretrain: True
  pretrain_ck: ./ts_context_logs/best.pth
  image_size: [64, 64] #图片大小
  patch_size: [8, 8] #图片分割大小
  pe_type: learned #相对位置
  use_glu: True #glu激活函数
  freq_type: lucidrains
  max_freq: 128
  use_self_attention: True
  num_mlp_heads: 1

  ctx_masking_ratio: 0
  ts_masking_ratio: 0 #0.15

  ctx_dim: 512
  ctx_depth: 8
  ctx_tubelet: 6
  ctx_channels: 5 #34使用dp时为23，不使用为34，使用7个光谱通道时18
#  ctx_heads: 12
#  ctx_mlp_ratio: 4
#  ctx_dim_head: 64
  ctx_dropout: 0
  ctx_droppath: 0.2

  mix_dim: 512
  mix_depth: 4
  mix_heads: 6
  mix_mlp_ratio: 4
  mix_dim_head: 64
  mix_dropout: 0.2

  # These hyperparameters apply to the encoding transformers and cross-attention
  dim: 512
  depth: 4
  heads: 6
  mlp_ratio: 4
  dim_head: 64
  dropout: 0.2

  ts_channels: 8
  ts_length: 48
  out_dim: 1

  # These only apply to the decoding transformer
  decoder_dim: 128
  decoder_depth: 4
  decoder_heads: 6
  decoder_dim_head: 128

#  time_coords_encoder:
#    _target_: src.models.ZSIF_modules.positional_encoding.Cyclical_embedding
#    frequencies: [12, 31, 24, 60]


optimizer:
  lr: 2e-4
  weight_decay: 0
  betas: [ 0.9, 0.999 ]

early_stop:
  _target_: src.utils.tools.EarlyStopping
  patience: 10
  verbose: True

scheduler:
  _target_: timm.scheduler.CosineLRScheduler
  _partial_: true
  t_initial: 10
  lr_min: 1e-7
  warmup_t: 0
#  factor: 0.7
#  _target_: src.optim.cosine_warmup.CosineWarmupScheduler
#  _partial_: true
#  warmup: 2
#  max_iters: 14
#  verbose: True
#  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
#  _partial_: true
#  T_max: 10
#  eta_min: 1e-7
#  _target_: torch.optim.lr_scheduler.OneCycleLR
#  _partial_: true
#  steps_per_epoch: 467
#  epochs: 30
#  max_lr: 1e-4


criterion:
  _target_: torch.nn.MSELoss
#  _target_: torch.nn.SmoothL1Loss
#  beta: 90
#  _target_: src.robust_loss_pytorch.adaptive.AdaptiveLossFunction
#  num_dims: 1
#  float_dtype: torch.float32
#  alpha_hi: 3.0
#monitor: val/loss

hyparams:
  train_epoch: 13
  seq_len: 48
  label_len: 0
  pred_len: 48
  use_amp: True
  use_dp: False
#  resume: True
  resume: False
  resume_ck: ./ts_context_logs/ZSIF/2024-02-29_15-42-15/checkpoints/last.pth
  checkpoint: ${paths.output_dir}/checkpoints/
  output_attention: False # Whether to output attention in the encoder
  patch_size: [8, 8]
  test_resume: ./ts_context_logs/ZSIF/2024-02-16_20-35-16/checkpoints
  test_result: ${paths.output_dir}/test_result/

wandb_para:
  name: "ZSIF_${now:%Y-%m-%d}_${now:%H-%M-%S}" # name of the run (normally generated by wandb)
  dir: "${paths.output_dir}"
  mode: "offline"
#  mode: "online"
  id: null # pass correct id to resume experiment!
  project: "MMF_forecast"
  group: "ZSIF"